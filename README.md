# Masters-Thesis
Improving Emotion Detection and Music Recommendation Through Advanced Facial Recognition and Optimized Hyper-parameters Tuning

# Abstract
Facial expression recognition is an important component of human-computer interaction which enables systems to understand and respond to human emotions. This study investigates how hyper-parameters optimize the accuracy and flexibility of facial expression recognition models and their integration with a music recommendation system. The primary goal is to develop the personalized music recommendation model on seven types of different facial expressions and determine the impact of hyper-parameters such as learning rate, optimizers, batch size, number of epochs, and activation functions on model performance. In the research, Convolutional neural networks (CNN) with hyper-parameter tuning and other two pre-trained deep learning models ResNet50 and Xception with hyper-parameter tuning were applied, and analyzed the validation accuracy and validation loss. A complete design specification is shown that combines advanced facial recognition techniques with user-define function (UDF) music recommendation features. The accuracy of the model is 65% with the proposed CNN architecture, 51.75% with ResNet50, and 70% with Xception when we evaluated different models under various hyper-parameters. All the findings show that hyper-parameter tuning increases the performance of facial expression-based music recommendation systems and provides a valuable contribution to the development of more interactive and responsive user experiences.
